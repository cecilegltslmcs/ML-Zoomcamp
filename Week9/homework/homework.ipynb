{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-24 16:51:42.725232: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:51:43.580703: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-24 16:51:43.581907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-24 16:51:43.750284: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-24 16:51:44.092880: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-24 16:51:44.096727: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-24 16:51:46.435848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "#import tensorflow.lite as tflite\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tflite_runtime.interpreter as tflite\n",
    "from io import BytesIO\n",
    "from urllib import request\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"bees-wasps.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4szoqljh/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp4szoqljh/assets\n",
      "2023-11-24 16:51:50.972821: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2023-11-24 16:51:50.972883: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2023-11-24 16:51:50.973529: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp4szoqljh\n",
      "2023-11-24 16:51:50.974641: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2023-11-24 16:51:50.974658: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp4szoqljh\n",
      "2023-11-24 16:51:50.984352: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2023-11-24 16:51:50.984986: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2023-11-24 16:51:51.347451: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /tmp/tmp4szoqljh\n",
      "2023-11-24 16:51:51.355476: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 381948 microseconds.\n",
      "2023-11-24 16:51:51.426662: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
      " * 7 ARITH ops\n",
      "\n",
      "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open('bees-wasps.tflite', 'wb') as f_out:\n",
    "    f_out.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 43Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "interpreter = tflite.Interpreter(model_path=\"bees-wasps.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    with request.urlopen(url) as resp:\n",
    "        buffer = resp.read()\n",
    "    stream = BytesIO(buffer)\n",
    "    img = Image.open(stream)\n",
    "    return img\n",
    "\n",
    "\n",
    "def prepare_image(img, target_size):\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = img.resize(target_size, Image.NEAREST)\n",
    "    return img\n",
    "\n",
    "def preprocess_input(x):\n",
    "    x /= 255\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = download_image(\"https://habrastorage.org/webt/rt/d9/dh/rtd9dhsmhwrdezeldzoqgijdg8a.jpeg\")\n",
    "input_size = (150, 150)\n",
    "\n",
    "img = prepare_image(image, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(img, dtype='float32')\n",
    "X = np.array([x])\n",
    "\n",
    "X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.94509804, 0.9098039 , 0.8509804 ],\n",
       "         [0.9372549 , 0.92156863, 0.9764706 ],\n",
       "         [0.9137255 , 0.8980392 , 0.95686275],\n",
       "         ...,\n",
       "         [0.2901961 , 0.33333334, 0.16470589],\n",
       "         [0.34901962, 0.40784314, 0.15294118],\n",
       "         [0.29803923, 0.36078432, 0.11764706]],\n",
       "\n",
       "        [[0.9490196 , 0.9098039 , 0.8627451 ],\n",
       "         [0.91764706, 0.9098039 , 0.9607843 ],\n",
       "         [0.9019608 , 0.89411765, 0.9490196 ],\n",
       "         ...,\n",
       "         [0.27450982, 0.3372549 , 0.16078432],\n",
       "         [0.4627451 , 0.5058824 , 0.19607843],\n",
       "         [0.4509804 , 0.49411765, 0.18431373]],\n",
       "\n",
       "        [[0.92941177, 0.88235295, 0.81960785],\n",
       "         [0.9137255 , 0.9098039 , 0.9647059 ],\n",
       "         [0.90588236, 0.89411765, 0.9607843 ],\n",
       "         ...,\n",
       "         [0.32156864, 0.3764706 , 0.1764706 ],\n",
       "         [0.49803922, 0.5294118 , 0.20392157],\n",
       "         [0.43137255, 0.46666667, 0.21176471]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03137255, 0.06666667, 0.04705882],\n",
       "         [0.02352941, 0.08627451, 0.04705882],\n",
       "         [0.08235294, 0.08235294, 0.08235294],\n",
       "         ...,\n",
       "         [0.44313726, 0.36078432, 0.04313726],\n",
       "         [0.16470589, 0.18039216, 0.11372549],\n",
       "         [0.11764706, 0.15686275, 0.11372549]],\n",
       "\n",
       "        [[0.03137255, 0.06666667, 0.04705882],\n",
       "         [0.07843138, 0.11764706, 0.08627451],\n",
       "         [0.05490196, 0.09803922, 0.08235294],\n",
       "         ...,\n",
       "         [0.32941177, 0.26666668, 0.06666667],\n",
       "         [0.12156863, 0.13333334, 0.09803922],\n",
       "         [0.09411765, 0.11372549, 0.09019608]],\n",
       "\n",
       "        [[0.01960784, 0.03921569, 0.02352941],\n",
       "         [0.08627451, 0.11372549, 0.08235294],\n",
       "         [0.10196079, 0.12156863, 0.09411765],\n",
       "         ...,\n",
       "         [0.16862746, 0.17254902, 0.10196079],\n",
       "         [0.13333334, 0.15686275, 0.11764706],\n",
       "         [0.09803922, 0.11764706, 0.09019608]]]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.9450980"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter.set_tensor(input_index, X)\n",
    "interpreter.invoke()\n",
    "\n",
    "preds = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6592137]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 662Mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer:* 0.4458"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
